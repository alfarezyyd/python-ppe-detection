{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e4c314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotation(label_path):\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    if not lines or not lines[0].strip():\n",
    "        print(f\"[INFO] File label kosong (tidak ada PPE): {label_path}\")\n",
    "        # bisa return bbox dummy dengan class 0 atau None tergantung use case\n",
    "        return 0, [0.5, 0.5, 0.1, 0.1]\n",
    "\n",
    "    try:\n",
    "        parts = lines[0].strip().split()\n",
    "        class_id = int(parts[0])\n",
    "        bbox = list(map(float, parts[1:5]))\n",
    "        return class_id, bbox\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Gagal parsing label di {label_path}: {e}\")\n",
    "        return 0, [0.5, 0.5, 0.1, 0.1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28166fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class YoloDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, image_dir, label_dir, batch_size=16, img_size=224, num_classes=8):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.num_classes = num_classes\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_files = self.image_files[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        images = []\n",
    "        classes = []\n",
    "        bboxes = []\n",
    "        \n",
    "        for file in batch_files:\n",
    "            # Load and preprocess image\n",
    "            img_path = os.path.join(self.image_dir, file)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "            img = img / 255.0\n",
    "            images.append(img)\n",
    "            \n",
    "            # Load annotation\n",
    "            txt_file = file.replace('.jpg', '.txt')\n",
    "            class_id, bbox = load_annotation(os.path.join(self.label_dir, txt_file))\n",
    "            classes.append(class_id)\n",
    "            bboxes.append(bbox)\n",
    "        \n",
    "        images = np.array(images, dtype=np.float32)\n",
    "        classes = tf.keras.utils.to_categorical(classes, num_classes=self.num_classes)\n",
    "        bboxes = np.array(bboxes, dtype=np.float32)\n",
    "        \n",
    "        return images, {'class_output': classes, 'bbox_output': bboxes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7016a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_model(input_shape=(224,224,3), num_classes=8):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Backbone CNN sederhana\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Conv2D(128, (3,3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    \n",
    "    # Output klasifikasi\n",
    "    class_output = layers.Dense(num_classes, activation='softmax', name='class_output')(x)\n",
    "    \n",
    "    # Output bounding box (x_center, y_center, width, height)\n",
    "    bbox_output = layers.Dense(4, activation='sigmoid', name='bbox_output')(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=[class_output, bbox_output])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d50e1cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m63/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m10s\u001b[0m 697ms/step - bbox_output_loss: 0.0399 - bbox_output_mse: 0.0399 - class_output_accuracy: 0.5451 - class_output_loss: 2.1933 - loss: 2.2332[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 718ms/step - bbox_output_loss: 0.0382 - bbox_output_mse: 0.0382 - class_output_accuracy: 0.5583 - class_output_loss: 2.0331 - loss: 2.0713 - val_bbox_output_loss: 0.0348 - val_bbox_output_mse: 0.0348 - val_class_output_accuracy: 0.6786 - val_class_output_loss: 0.8635 - val_loss: 0.8983\n",
      "Epoch 2/20\n",
      "\u001b[1m31/78\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 715ms/step - bbox_output_loss: 0.0261 - bbox_output_mse: 0.0261 - class_output_accuracy: 0.6463 - class_output_loss: 0.9905 - loss: 1.0165[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 819ms/step - bbox_output_loss: 0.0249 - bbox_output_mse: 0.0249 - class_output_accuracy: 0.6359 - class_output_loss: 0.9805 - loss: 1.0055 - val_bbox_output_loss: 0.0385 - val_bbox_output_mse: 0.0385 - val_class_output_accuracy: 0.6964 - val_class_output_loss: 0.7490 - val_loss: 0.7875\n",
      "Epoch 3/20\n",
      "\u001b[1m30/78\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 838ms/step - bbox_output_loss: 0.0255 - bbox_output_mse: 0.0255 - class_output_accuracy: 0.7137 - class_output_loss: 0.7482 - loss: 0.7737[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 826ms/step - bbox_output_loss: 0.0239 - bbox_output_mse: 0.0239 - class_output_accuracy: 0.7254 - class_output_loss: 0.7375 - loss: 0.7614 - val_bbox_output_loss: 0.0238 - val_bbox_output_mse: 0.0238 - val_class_output_accuracy: 0.7768 - val_class_output_loss: 0.7222 - val_loss: 0.7460\n",
      "Epoch 4/20\n",
      "\u001b[1m64/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m9s\u001b[0m 672ms/step - bbox_output_loss: 0.0198 - bbox_output_mse: 0.0198 - class_output_accuracy: 0.8575 - class_output_loss: 0.3948 - loss: 0.4146 [INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 721ms/step - bbox_output_loss: 0.0201 - bbox_output_mse: 0.0201 - class_output_accuracy: 0.8553 - class_output_loss: 0.4009 - loss: 0.4210 - val_bbox_output_loss: 0.0213 - val_bbox_output_mse: 0.0213 - val_class_output_accuracy: 0.7946 - val_class_output_loss: 0.6155 - val_loss: 0.6368\n",
      "Epoch 5/20\n",
      "\u001b[1m26/78\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 924ms/step - bbox_output_loss: 0.0152 - bbox_output_mse: 0.0152 - class_output_accuracy: 0.9451 - class_output_loss: 0.1809 - loss: 0.1960[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 904ms/step - bbox_output_loss: 0.0165 - bbox_output_mse: 0.0165 - class_output_accuracy: 0.9385 - class_output_loss: 0.1915 - loss: 0.2079 - val_bbox_output_loss: 0.0216 - val_bbox_output_mse: 0.0216 - val_class_output_accuracy: 0.7946 - val_class_output_loss: 0.7451 - val_loss: 0.7667\n",
      "Epoch 6/20\n",
      "\u001b[1m48/78\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 643ms/step - bbox_output_loss: 0.0119 - bbox_output_mse: 0.0119 - class_output_accuracy: 0.9678 - class_output_loss: 0.1092 - loss: 0.1210[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 656ms/step - bbox_output_loss: 0.0120 - bbox_output_mse: 0.0120 - class_output_accuracy: 0.9719 - class_output_loss: 0.0972 - loss: 0.1091 - val_bbox_output_loss: 0.0223 - val_bbox_output_mse: 0.0223 - val_class_output_accuracy: 0.7768 - val_class_output_loss: 0.8237 - val_loss: 0.8460\n",
      "Epoch 7/20\n",
      "\u001b[1m 7/78\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 612ms/step - bbox_output_loss: 0.0096 - bbox_output_mse: 0.0096 - class_output_accuracy: 0.9805 - class_output_loss: 0.0459 - loss: 0.0555[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 621ms/step - bbox_output_loss: 0.0106 - bbox_output_mse: 0.0106 - class_output_accuracy: 0.9815 - class_output_loss: 0.0589 - loss: 0.0696 - val_bbox_output_loss: 0.0211 - val_bbox_output_mse: 0.0211 - val_class_output_accuracy: 0.7589 - val_class_output_loss: 0.9804 - val_loss: 1.0016\n",
      "Epoch 8/20\n",
      "\u001b[1m42/78\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 890ms/step - bbox_output_loss: 0.0081 - bbox_output_mse: 0.0081 - class_output_accuracy: 0.9803 - class_output_loss: 0.0313 - loss: 0.0394[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - bbox_output_loss: 0.0080 - bbox_output_mse: 0.0080 - class_output_accuracy: 0.9819 - class_output_loss: 0.0346 - loss: 0.0426 - val_bbox_output_loss: 0.0220 - val_bbox_output_mse: 0.0220 - val_class_output_accuracy: 0.7589 - val_class_output_loss: 0.8995 - val_loss: 0.9215\n",
      "Epoch 9/20\n",
      "\u001b[1m68/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 784ms/step - bbox_output_loss: 0.0059 - bbox_output_mse: 0.0059 - class_output_accuracy: 0.9952 - class_output_loss: 0.0205 - loss: 0.0264[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 774ms/step - bbox_output_loss: 0.0059 - bbox_output_mse: 0.0059 - class_output_accuracy: 0.9951 - class_output_loss: 0.0208 - loss: 0.0267 - val_bbox_output_loss: 0.0220 - val_bbox_output_mse: 0.0220 - val_class_output_accuracy: 0.7411 - val_class_output_loss: 0.9726 - val_loss: 0.9946\n",
      "Epoch 10/20\n",
      "\u001b[1m50/78\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 633ms/step - bbox_output_loss: 0.0054 - bbox_output_mse: 0.0054 - class_output_accuracy: 0.9938 - class_output_loss: 0.0232 - loss: 0.0286[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 706ms/step - bbox_output_loss: 0.0054 - bbox_output_mse: 0.0054 - class_output_accuracy: 0.9942 - class_output_loss: 0.0209 - loss: 0.0263 - val_bbox_output_loss: 0.0232 - val_bbox_output_mse: 0.0232 - val_class_output_accuracy: 0.7679 - val_class_output_loss: 1.0664 - val_loss: 1.0896\n",
      "Epoch 11/20\n",
      "\u001b[1m13/78\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 934ms/step - bbox_output_loss: 0.0052 - bbox_output_mse: 0.0052 - class_output_accuracy: 1.0000 - class_output_loss: 0.0065 - loss: 0.0117[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 700ms/step - bbox_output_loss: 0.0053 - bbox_output_mse: 0.0053 - class_output_accuracy: 0.9972 - class_output_loss: 0.0101 - loss: 0.0155 - val_bbox_output_loss: 0.0201 - val_bbox_output_mse: 0.0201 - val_class_output_accuracy: 0.7500 - val_class_output_loss: 1.0490 - val_loss: 1.0691\n",
      "Epoch 12/20\n",
      "\u001b[1m62/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m9s\u001b[0m 615ms/step - bbox_output_loss: 0.0052 - bbox_output_mse: 0.0052 - class_output_accuracy: 0.9997 - class_output_loss: 0.0051 - loss: 0.0102 [INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 644ms/step - bbox_output_loss: 0.0053 - bbox_output_mse: 0.0053 - class_output_accuracy: 0.9995 - class_output_loss: 0.0053 - loss: 0.0105 - val_bbox_output_loss: 0.0216 - val_bbox_output_mse: 0.0216 - val_class_output_accuracy: 0.7589 - val_class_output_loss: 1.3324 - val_loss: 1.3540\n",
      "Epoch 13/20\n",
      "\u001b[1m37/78\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 638ms/step - bbox_output_loss: 0.0056 - bbox_output_mse: 0.0056 - class_output_accuracy: 0.9809 - class_output_loss: 0.0393 - loss: 0.0450[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 660ms/step - bbox_output_loss: 0.0058 - bbox_output_mse: 0.0058 - class_output_accuracy: 0.9870 - class_output_loss: 0.0273 - loss: 0.0331 - val_bbox_output_loss: 0.0199 - val_bbox_output_mse: 0.0199 - val_class_output_accuracy: 0.7679 - val_class_output_loss: 1.0060 - val_loss: 1.0259\n",
      "Epoch 14/20\n",
      "\u001b[1m46/78\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 882ms/step - bbox_output_loss: 0.0056 - bbox_output_mse: 0.0056 - class_output_accuracy: 0.9892 - class_output_loss: 0.0241 - loss: 0.0297[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 852ms/step - bbox_output_loss: 0.0054 - bbox_output_mse: 0.0054 - class_output_accuracy: 0.9904 - class_output_loss: 0.0215 - loss: 0.0269 - val_bbox_output_loss: 0.0198 - val_bbox_output_mse: 0.0198 - val_class_output_accuracy: 0.7679 - val_class_output_loss: 1.0152 - val_loss: 1.0350\n",
      "Epoch 15/20\n",
      "\u001b[1m16/78\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 590ms/step - bbox_output_loss: 0.0048 - bbox_output_mse: 0.0048 - class_output_accuracy: 0.9940 - class_output_loss: 0.0096 - loss: 0.0144[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - bbox_output_loss: 0.0051 - bbox_output_mse: 0.0051 - class_output_accuracy: 0.9966 - class_output_loss: 0.0076 - loss: 0.0127 - val_bbox_output_loss: 0.0188 - val_bbox_output_mse: 0.0188 - val_class_output_accuracy: 0.7500 - val_class_output_loss: 0.9214 - val_loss: 0.9402\n",
      "Epoch 16/20\n",
      "\u001b[1m23/78\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 952ms/step - bbox_output_loss: 0.0041 - bbox_output_mse: 0.0041 - class_output_accuracy: 1.0000 - class_output_loss: 0.0032 - loss: 0.0074[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 793ms/step - bbox_output_loss: 0.0043 - bbox_output_mse: 0.0043 - class_output_accuracy: 0.9996 - class_output_loss: 0.0031 - loss: 0.0074 - val_bbox_output_loss: 0.0191 - val_bbox_output_mse: 0.0191 - val_class_output_accuracy: 0.7679 - val_class_output_loss: 0.9937 - val_loss: 1.0128\n",
      "Epoch 17/20\n",
      "\u001b[1m28/78\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 774ms/step - bbox_output_loss: 0.0033 - bbox_output_mse: 0.0033 - class_output_accuracy: 1.0000 - class_output_loss: 0.0028 - loss: 0.0062[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 833ms/step - bbox_output_loss: 0.0033 - bbox_output_mse: 0.0033 - class_output_accuracy: 0.9998 - class_output_loss: 0.0028 - loss: 0.0061 - val_bbox_output_loss: 0.0211 - val_bbox_output_mse: 0.0211 - val_class_output_accuracy: 0.7768 - val_class_output_loss: 1.0950 - val_loss: 1.1161\n",
      "Epoch 18/20\n",
      "\u001b[1m70/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 707ms/step - bbox_output_loss: 0.0042 - bbox_output_mse: 0.0042 - class_output_accuracy: 0.9986 - class_output_loss: 0.0031 - loss: 0.0073[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 706ms/step - bbox_output_loss: 0.0041 - bbox_output_mse: 0.0041 - class_output_accuracy: 0.9986 - class_output_loss: 0.0031 - loss: 0.0072 - val_bbox_output_loss: 0.0195 - val_bbox_output_mse: 0.0195 - val_class_output_accuracy: 0.7768 - val_class_output_loss: 1.0950 - val_loss: 1.1145\n",
      "Epoch 19/20\n",
      "\u001b[1m30/78\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 757ms/step - bbox_output_loss: 0.0033 - bbox_output_mse: 0.0033 - class_output_accuracy: 0.9996 - class_output_loss: 0.0049 - loss: 0.0081[INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 768ms/step - bbox_output_loss: 0.0035 - bbox_output_mse: 0.0035 - class_output_accuracy: 0.9985 - class_output_loss: 0.0064 - loss: 0.0099 - val_bbox_output_loss: 0.0200 - val_bbox_output_mse: 0.0200 - val_class_output_accuracy: 0.7679 - val_class_output_loss: 1.0772 - val_loss: 1.0972\n",
      "Epoch 20/20\n",
      "\u001b[1m40/78\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 598ms/step - bbox_output_loss: 0.0042 - bbox_output_mse: 0.0042 - class_output_accuracy: 0.9994 - class_output_loss: 0.0012 - loss: 0.0054   [INFO] File label kosong (tidak ada PPE): dataset/train/labels/image_244_jpg.rf.f858a0066ef9b0dd3a830074e4d444f9.txt\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 614ms/step - bbox_output_loss: 0.0039 - bbox_output_mse: 0.0039 - class_output_accuracy: 0.9986 - class_output_loss: 0.0032 - loss: 0.0071 - val_bbox_output_loss: 0.0191 - val_bbox_output_mse: 0.0191 - val_class_output_accuracy: 0.7768 - val_class_output_loss: 1.0669 - val_loss: 1.0859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x177f96910>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buat model\n",
    "model = create_model()\n",
    "\n",
    "# Compile dengan loss yang berbeda untuk 2 output\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'class_output': 'categorical_crossentropy',\n",
    "        'bbox_output': 'mse'\n",
    "    },\n",
    "    metrics={\n",
    "        'class_output': 'accuracy',\n",
    "        'bbox_output': 'mse'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Direktori data (sesuaikan)\n",
    "train_image_dir = 'dataset/train/images'\n",
    "train_label_dir = 'dataset/train/labels'\n",
    "val_image_dir = 'dataset/valid/images'\n",
    "val_label_dir = 'dataset/valid/labels'\n",
    "\n",
    "# Buat dataset generator\n",
    "train_gen = YoloDataset(train_image_dir, train_label_dir, batch_size=16, img_size=224, num_classes=8)\n",
    "val_gen = YoloDataset(val_image_dir, val_label_dir, batch_size=16, img_size=224, num_classes=8)\n",
    "\n",
    "# Training\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f309dedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"ppe_model.h5\")\n",
    "\n",
    "model.save(\"ppe_model.keras\")  # ini format baru Keras 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc339da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - bbox_output_loss: 0.0323 - bbox_output_mse: 0.0323 - class_output_accuracy: 0.6432 - class_output_loss: 1.6373 - loss: 1.6695\n",
      "Total Loss: 1.7123584747314453\n",
      "Class Loss: 1.681443691253662\n",
      "BBox Loss: 0.03091474436223507\n",
      "Class Accuracy: 0.03091474436223507\n",
      "BBox MSE: 0.6458333134651184\n"
     ]
    }
   ],
   "source": [
    "# Buat test generator\n",
    "test_image_dir = 'dataset/test/images'\n",
    "test_label_dir = 'dataset/test/labels'\n",
    "\n",
    "test_gen = YoloDataset(test_image_dir, test_label_dir, batch_size=16, img_size=224, num_classes=8)\n",
    "\n",
    "# Evaluasi model\n",
    "loss, class_loss, bbox_loss, class_acc, bbox_mse = model.evaluate(test_gen, return_dict=False)\n",
    "\n",
    "print(\"Total Loss:\", loss)\n",
    "print(\"Class Loss:\", class_loss)\n",
    "print(\"BBox Loss:\", bbox_loss)\n",
    "print(\"Class Accuracy:\", class_acc)\n",
    "print(\"BBox MSE:\", bbox_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c411b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
